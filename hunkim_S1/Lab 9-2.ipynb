{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/pandas/compat/__init__.py:84: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "/usr/local/lib/python3.7/site-packages/pandas/compat/__init__.py:84: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "g1 = tf.Graph()\n",
    "with g1.as_default() as graph:\n",
    "    \n",
    "    x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
    "    y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)\n",
    "       \n",
    "    X = tf.compat.v1.placeholder(tf.float32)\n",
    "    Y = tf.compat.v1.placeholder(tf.float32)\n",
    "    \n",
    "    with tf.name_scope(\"layer1\") as scope:\n",
    "    \n",
    "        W1 = tf.Variable(tf.compat.v1.random_normal([2, 2]), name = 'weight1')\n",
    "        b1 = tf.Variable(tf.compat.v1.random_normal([2]), name = 'bias1')\n",
    "        layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "        \n",
    "        w1_hist = tf.compat.v1.summary.histogram(\"weights1\", W1)\n",
    "        b1_hist = tf.compat.v1.summary.histogram(\"biases1\", b1)\n",
    "        layer1_hist = tf.compat.v1.summary.histogram(\"layer1\", layer1)\n",
    "    \n",
    "    with tf.name_scope(\"layer2\") as scope:\n",
    "    \n",
    "        W2 = tf.Variable(tf.compat.v1.random_normal([2, 1]), name = 'weight2')\n",
    "        b2 = tf.Variable(tf.compat.v1.random_normal([1]), name = 'bias2')\n",
    "        hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "        w2_hist = tf.compat.v1.summary.histogram(\"weights2\", W2)\n",
    "        b2_hist = tf.compat.v1.summary.histogram(\"biases2\", b2)\n",
    "        hypothesis_hist = tf.compat.v1.summary.histogram(\"hypothesis\", hypothesis)\n",
    "    \n",
    "    cost = -tf.reduce_mean(Y * tf.compat.v1.log(hypothesis) + (1 - Y) * tf.compat.v1.log(1 - hypothesis))\n",
    "    cost_sum = tf.compat.v1.summary.scalar(\"cost\", cost)\n",
    "    train = tf.compat.v1.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "    \n",
    "    predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))    \n",
    "    \n",
    "    init_op = tf.compat.v1.global_variables_initializer()\n",
    "    \n",
    "    #########################################################################   \n",
    "    merged_summary = tf.compat.v1.summary.merge_all()\n",
    "    writer = tf.compat.v1.summary.FileWriter('./logs/xor_logs')\n",
    "    \n",
    "sess = tf.compat.v1.Session(graph = g1)\n",
    "sess.run(init_op)\n",
    "\n",
    "writer.add_graph(sess.graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.907387\n",
      "100 0.6998233\n",
      "200 0.6983017\n",
      "300 0.69726944\n",
      "400 0.6964883\n",
      "500 0.695884\n",
      "600 0.69540656\n",
      "700 0.69502187\n",
      "800 0.69470584\n",
      "900 0.6944411\n",
      "1000 0.6942148\n",
      "1100 0.6940172\n",
      "1200 0.69384074\n",
      "1300 0.69367945\n",
      "1400 0.69352806\n",
      "1500 0.6933824\n",
      "1600 0.6932381\n",
      "1700 0.69309133\n",
      "1800 0.69293797\n",
      "1900 0.6927735\n",
      "2000 0.69259304\n",
      "2100 0.69239056\n",
      "2200 0.692159\n",
      "2300 0.6918896\n",
      "2400 0.69157153\n",
      "2500 0.69119096\n",
      "2600 0.6907307\n",
      "2700 0.69016874\n",
      "2800 0.68947685\n",
      "2900 0.6886198\n",
      "3000 0.6875525\n",
      "3100 0.6862187\n",
      "3200 0.6845479\n",
      "3300 0.6824532\n",
      "3400 0.6798278\n",
      "3500 0.67654335\n",
      "3600 0.6724481\n",
      "3700 0.6673721\n",
      "3800 0.66113883\n",
      "3900 0.6535922\n",
      "4000 0.64463973\n",
      "4100 0.6343013\n",
      "4200 0.62274075\n",
      "4300 0.6102509\n",
      "4400 0.59719044\n",
      "4500 0.5838997\n",
      "4600 0.5706335\n",
      "4700 0.55753404\n",
      "4800 0.5446303\n",
      "4900 0.5318461\n",
      "5000 0.5190053\n",
      "5100 0.5058322\n",
      "5200 0.49195102\n",
      "5300 0.47688836\n",
      "5400 0.4600963\n",
      "5500 0.44102907\n",
      "5600 0.4192953\n",
      "5700 0.39483613\n",
      "5800 0.3680191\n",
      "5900 0.3395908\n",
      "6000 0.31053174\n",
      "6100 0.28187972\n",
      "6200 0.2545556\n",
      "6300 0.22923648\n",
      "6400 0.20630783\n",
      "6500 0.18589306\n",
      "6600 0.16792259\n",
      "6700 0.15221012\n",
      "6800 0.13851556\n",
      "6900 0.1265852\n",
      "7000 0.11617689\n",
      "7100 0.10707219\n",
      "7200 0.09907984\n",
      "7300 0.092035875\n",
      "7400 0.08580156\n",
      "7500 0.08025995\n",
      "7600 0.07531298\n",
      "7700 0.07087829\n",
      "7800 0.066886514\n",
      "7900 0.06327957\n",
      "8000 0.060008124\n",
      "8100 0.057030626\n",
      "8200 0.054311402\n",
      "8300 0.051820256\n",
      "8400 0.04953116\n",
      "8500 0.047421753\n",
      "8600 0.045472674\n",
      "8700 0.043667212\n",
      "8800 0.041990694\n",
      "8900 0.040430427\n",
      "9000 0.038975246\n",
      "9100 0.037615187\n",
      "9200 0.03634171\n",
      "9300 0.035146926\n",
      "9400 0.034024213\n",
      "9500 0.032967303\n",
      "9600 0.03197086\n",
      "9700 0.031029971\n",
      "9800 0.030140273\n",
      "9900 0.029297788\n",
      "10000 0.028498996\n"
     ]
    }
   ],
   "source": [
    "for step in range(10001):\n",
    "    _, summary, cost_val = sess.run(\n",
    "        [train, merged_summary, cost], feed_dict={X: x_data, Y: y_data}\n",
    "    )\n",
    "    writer.add_summary(summary, global_step=step)\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        print(step, cost_val)\n",
    "\n",
    "    # Accuracy report\n",
    "h, p, a = sess.run(\n",
    "    [hypothesis, predicted, accuracy], feed_dict={X: x_data, Y: y_data}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
